company_size = as.factor(company_size),
remote_ratio = as.factor(remote_ratio))
Q1 <- quantile(salaries$salary_in_usd, 0.25)
Q3 <- quantile(salaries$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
salaries <- salaries[salaries$salary_in_usd >= lower_bound & salaries$salary_in_usd <= upper_bound, ]
rm(IQR, lower_bound, Q1, Q3, upper_bound)
categorical_data <- salaries[, c("experience_level", "employment_type", "job_title", "remote_ratio","company_location", "company_size")]
dummy_cols <- dummyVars(" ~ .", data = categorical_data)
encoded_data <- predict(dummy_cols, newdata = categorical_data)
clean_salaries <- as.data.frame(cbind(salaries[, c("salary_in_usd")], encoded_data))
colnames(clean_salaries)[1] <- "salary"
rm(categorical_data, dummy_cols, encoded_data)
clean_salaries$salary_category <- cut(clean_salaries$salary,
breaks = 10,
include.lowest = TRUE,
dig.lab = 10)
clean_salaries$salary <- NULL
View(clean_salaries)
View(clean_salaries)
table(clean_salaries$salary_category)
levels(clean_salaries$salary_category)
clean_salaries$salary_category <- as.integer(clean_salaries$salary_category) - 1
set.seed(11)
split <- createDataPartition(clean_salaries$salary_category, p = 0.7, list = FALSE)
train_data <- clean_salaries[split, ]
test_data <- clean_salaries[-split, ]
train_labels <- train_data$salary_category
test_labels <- test_data$salary_category
train_data <- train_data[, !(colnames(train_data) %in% c("salary_category"))]
test_data <- test_data[, !(colnames(test_data) %in% c("salary_category"))]
train_matrix <- xgb.DMatrix(data = as.matrix(train_data), label = train_labels)
test_matrix <- xgb.DMatrix(data = as.matrix(test_data), label = test_labels)
#default parameters
params <- list(booster = "gbtree",
objective = "multi:softmax",
num_class = length(unique(train_labels)),
eta=0.3,
gamma=0,
max_depth=6,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
xgbcv <- xgb.cv(params = params,
data = train_matrix,
nrounds = 100,
nfold = 5,
showsd = T,
stratified = T,
print.every.n = 10,
early.stop.round = 20,
maximize = F)
best_iteration <- 23
final_model <- xgboost(
data = train_matrix,
booster = "gbtree",
objective = "multi:softmax",
num_class = length(unique(train_labels)),
eta = 0.3,
gamma = 0,
max_depth = 6,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
nrounds = best_iteration
)
test_predictions <- predict(final_model, newdata = test_matrix)
mean(test_predictions == test_labels)
# Chunk 1
library(tidyverse)
library(caret)
library(xgboost)
salaries <- read.csv("salaries.csv")
# Chunk 2
# salaries <- salaries %>%
#   filter(work_year == 2023, employee_residence == "US")
salaries <- salaries %>%
filter(work_year == 2023)
salaries <- salaries %>%
select(!(c(work_year, salary, salary_currency, employee_residence)))
# Chunk 3
job_counts <- salaries %>%
count(job_title)
job_titles <- as.vector(job_counts[which(job_counts$n > 0.01*nrow(salaries)),1])
salaries <- salaries %>%
filter(job_title %in% job_titles)
rm(job_counts, job_titles)
# Chunk 4
salaries <- salaries %>%
mutate(experience_level = as.factor(experience_level),
employment_type = as.factor(employment_type),
job_title = as.factor(job_title),
company_location = as.factor(company_location),
company_size = as.factor(company_size),
remote_ratio = as.factor(remote_ratio))
# Chunk 5
Q1 <- quantile(salaries$salary_in_usd, 0.25)
Q3 <- quantile(salaries$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
salaries <- salaries[salaries$salary_in_usd >= lower_bound & salaries$salary_in_usd <= upper_bound, ]
rm(IQR, lower_bound, Q1, Q3, upper_bound)
# Chunk 6
categorical_data <- salaries[, c("experience_level", "employment_type", "job_title", "remote_ratio","company_location", "company_size")]
dummy_cols <- dummyVars(" ~ .", data = categorical_data)
encoded_data <- predict(dummy_cols, newdata = categorical_data)
clean_salaries <- as.data.frame(cbind(salaries[, c("salary_in_usd")], encoded_data))
colnames(clean_salaries)[1] <- "salary"
rm(categorical_data, dummy_cols, encoded_data)
clean_salaries$salary_category <- cut(clean_salaries$salary,
breaks = 5,
include.lowest = TRUE,
dig.lab = 10)
clean_salaries$salary <- NULL
table(clean_salaries$salary_category)
levels(clean_salaries$salary_category)
clean_salaries$salary_category <- as.integer(clean_salaries$salary_category) - 1
set.seed(11)
split <- createDataPartition(clean_salaries$salary_category, p = 0.7, list = FALSE)
train_data <- clean_salaries[split, ]
test_data <- clean_salaries[-split, ]
train_labels <- train_data$salary_category
test_labels <- test_data$salary_category
train_data <- train_data[, !(colnames(train_data) %in% c("salary_category"))]
test_data <- test_data[, !(colnames(test_data) %in% c("salary_category"))]
train_matrix <- xgb.DMatrix(data = as.matrix(train_data), label = train_labels)
test_matrix <- xgb.DMatrix(data = as.matrix(test_data), label = test_labels)
#default parameters
params <- list(booster = "gbtree",
objective = "multi:softmax",
num_class = length(unique(train_labels)),
eta=0.3,
gamma=0,
max_depth=6,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
xgbcv <- xgb.cv(params = params,
data = train_matrix,
nrounds = 100,
nfold = 5,
showsd = T,
stratified = T,
print.every.n = 10,
early.stop.round = 20,
maximize = F)
best_iteration <- 28
final_model <- xgboost(
data = train_matrix,
booster = "gbtree",
objective = "multi:softmax",
num_class = length(unique(train_labels)),
eta = 0.3,
gamma = 0,
max_depth = 6,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1,
nrounds = best_iteration
)
test_predictions <- predict(final_model, newdata = test_matrix)
mean(test_predictions == test_labels)
rm(params)
# Define a grid of parameters to search over
grid_params <- list(
eta = c(0.1, 0.01, 0.001),
max_depth = c(4, 6, 8),
min_child_weight = c(1, 5, 10),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
lambda = c(0, 0.1, 1),
alpha = c(0, 0.1, 1)
)
# Initialize an empty list to store results
results <- list()
# Perform grid search
for (param_set in expand.grid(grid_params)) {
# Combine the default parameters with the current parameter set
current_params <- c(params, param_set)
# Run cross-validation with the current parameter set
xgbcv <- xgb.cv(
params = current_params,
data = train_matrix,
nrounds = 100,
nfold = 5,
showsd = TRUE,
stratified = TRUE,
print.every.n = 10,
early.stop.round = 20,
maximize = FALSE
)
# Store the results for later analysis
results[[paste(param_set, collapse = "_")]] <- xgbcv$evaluation_log
}
#default parameters
params <- list(booster = "gbtree",
objective = "multi:softmax",
num_class = length(unique(train_labels)),
eta=0.3,
gamma=0,
max_depth=6,
min_child_weight=1,
subsample=1,
colsample_bytree=1)
# Define a grid of parameters to search over
grid_params <- list(
eta = c(0.1, 0.01, 0.001),
max_depth = c(4, 6, 8),
min_child_weight = c(1, 5, 10),
subsample = c(0.8, 1.0),
colsample_bytree = c(0.8, 1.0),
lambda = c(0, 0.1, 1),
alpha = c(0, 0.1, 1)
)
# Initialize an empty list to store results
results <- list()
# Perform grid search
for (param_set in expand.grid(grid_params)) {
# Combine the default parameters with the current parameter set
current_params <- c(params, param_set)
# Run cross-validation with the current parameter set
xgbcv <- xgb.cv(
params = current_params,
data = train_matrix,
nrounds = 100,
nfold = 5,
showsd = TRUE,
stratified = TRUE,
print.every.n = 10,
early.stop.round = 20,
maximize = FALSE
)
# Store the results for later analysis
results[[paste(param_set, collapse = "_")]] <- xgbcv$evaluation_log
}
# Perform grid search
for (i in seq_len(nrow(expand.grid(grid_params)))) {
# Combine the default parameters with the current parameter set
current_params <- c(params, as.list(expand.grid(grid_params)[i, ]))
# Run cross-validation with the current parameter set
xgbcv <- xgb.cv(
params = current_params,
data = train_matrix,
nrounds = 100,
nfold = 5,
showsd = TRUE,
stratified = TRUE,
print_every_n = 10,
early_stopping_rounds = 20,
maximize = FALSE
)
# Store the results for later analysis
results[[i]] <- xgbcv$evaluation_log
}
View(results)
# Identify the best parameter set
best_params <- names(results)[which.min(sapply(results, function(x) min(x$test_mlogloss.mean)))]
# Retrieve the best parameter set and results
best_params_values <- strsplit(best_params, "_")[[1]]
library(tidyverse)
library(caret)
library(xgboost)
salaries <- read.csv("salaries.csv")
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
Salary <- read.csv("salaries.csv")
# Set seed for reproducibility
set.seed(123)
# Sample indices for training set
train_indices <- sample(1:nrow(Salary), 0.8 * nrow(Salary))
# Create training and testing datasets
train_data <- Salary[train_indices, ]
test_data <- Salary[-train_indices, ]
# Convert factor variables to factors with consistent levels
factor_vars <- c("experience_level", "job_title", "salary_currency", "employee_residence", "company_size", "company_location", "employment_type")
for (var in factor_vars) {
train_data[[var]] <- as.factor(train_data[[var]])
test_data[[var]] <- as.factor(test_data[[var]])
}
# Ensure factor levels in newdata match the training data
for (var in factor_vars) {
test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# Build the model
tree_model <- rpart(salary_in_usd ~ work_year + experience_level + employment_type + job_title + employee_residence + remote_ratio + company_location + company_size, data = train_data)
plot(tree_model)
text(tree_model, digits=1)
rpart.plot(tree_model, extra = 1)
# Make predictions
predictions <- predict(tree_model, newdata = test_data)
# Extract actual salary values
actual_salary <- test_data$salary_in_usd
# Check for missing values
sum(is.na(actual_salary))
sum(is.na(predictions))
# Remove missing values
complete_cases <- complete.cases(actual_salary, predictions)
actual_salary <- actual_salary[complete_cases]
predictions <- predictions[complete_cases]
# Calculate RMSE
rmse <- sqrt(mean((predictions - actual_salary)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
Salary <- read.csv("salaries.csv")
Q1 <- quantile(Salary$salary_in_usd, 0.25)
Q3 <- quantile(Salary$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
Salary <- Salary[Salary$salary_in_usd >= lower_bound & Salary$salary_in_usd <= upper_bound, ]
# Set seed for reproducibility
set.seed(123)
# Sample indices for training set
train_indices <- sample(1:nrow(Salary), 0.8 * nrow(Salary))
# Create training and testing datasets
train_data <- Salary[train_indices, ]
test_data <- Salary[-train_indices, ]
# Convert factor variables to factors with consistent levels
factor_vars <- c("experience_level", "job_title", "salary_currency", "employee_residence", "company_size", "company_location", "employment_type")
for (var in factor_vars) {
train_data[[var]] <- as.factor(train_data[[var]])
test_data[[var]] <- as.factor(test_data[[var]])
}
# Ensure factor levels in newdata match the training data
for (var in factor_vars) {
test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# Build the model
tree_model <- rpart(salary_in_usd ~ work_year + experience_level + employment_type + job_title + employee_residence + remote_ratio + company_location + company_size, data = train_data)
plot(tree_model)
text(tree_model, digits=1)
rpart.plot(tree_model, extra = 1)
# Make predictions
predictions <- predict(tree_model, newdata = test_data)
# Extract actual salary values
actual_salary <- test_data$salary_in_usd
# Check for missing values
sum(is.na(actual_salary))
sum(is.na(predictions))
# Remove missing values
complete_cases <- complete.cases(actual_salary, predictions)
actual_salary <- actual_salary[complete_cases]
predictions <- predictions[complete_cases]
# Calculate RMSE
rmse <- sqrt(mean((predictions - actual_salary)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
Salary <- read.csv("salaries.csv")
Q1 <- quantile(Salary$salary_in_usd, 0.25)
Q3 <- quantile(Salary$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
Salary <- Salary[Salary$salary_in_usd >= lower_bound & Salary$salary_in_usd <= upper_bound, ]
Salary <- Salary %>%
filter(year == 2023)
Salary <- Salary %>%
filter(work_year == 2023)
# Set seed for reproducibility
set.seed(123)
# Sample indices for training set
train_indices <- sample(1:nrow(Salary), 0.8 * nrow(Salary))
# Create training and testing datasets
train_data <- Salary[train_indices, ]
test_data <- Salary[-train_indices, ]
# Convert factor variables to factors with consistent levels
factor_vars <- c("experience_level", "job_title", "salary_currency", "employee_residence", "company_size", "company_location", "employment_type")
for (var in factor_vars) {
train_data[[var]] <- as.factor(train_data[[var]])
test_data[[var]] <- as.factor(test_data[[var]])
}
# Ensure factor levels in newdata match the training data
for (var in factor_vars) {
test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# Build the model
tree_model <- rpart(salary_in_usd ~ work_year + experience_level + employment_type + job_title + employee_residence + remote_ratio + company_location + company_size, data = train_data)
plot(tree_model)
text(tree_model, digits=1)
rpart.plot(tree_model, extra = 1)
# Make predictions
predictions <- predict(tree_model, newdata = test_data)
# Extract actual salary values
actual_salary <- test_data$salary_in_usd
# Check for missing values
sum(is.na(actual_salary))
sum(is.na(predictions))
# Remove missing values
complete_cases <- complete.cases(actual_salary, predictions)
actual_salary <- actual_salary[complete_cases]
predictions <- predictions[complete_cases]
# Calculate RMSE
rmse <- sqrt(mean((predictions - actual_salary)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
Salary <- read.csv("salaries.csv")
Q1 <- quantile(Salary$salary_in_usd, 0.25)
Q3 <- quantile(Salary$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
Salary <- Salary[Salary$salary_in_usd >= lower_bound & Salary$salary_in_usd <= upper_bound, ]
Salary <- Salary %>%
filter(work_year %in% c(2022, 2023))
# Set seed for reproducibility
set.seed(123)
# Sample indices for training set
train_indices <- sample(1:nrow(Salary), 0.8 * nrow(Salary))
# Create training and testing datasets
train_data <- Salary[train_indices, ]
test_data <- Salary[-train_indices, ]
# Convert factor variables to factors with consistent levels
factor_vars <- c("experience_level", "job_title", "salary_currency", "employee_residence", "company_size", "company_location", "employment_type")
for (var in factor_vars) {
train_data[[var]] <- as.factor(train_data[[var]])
test_data[[var]] <- as.factor(test_data[[var]])
}
# Ensure factor levels in newdata match the training data
for (var in factor_vars) {
test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# Build the model
tree_model <- rpart(salary_in_usd ~ work_year + experience_level + employment_type + job_title + employee_residence + remote_ratio + company_location + company_size, data = train_data)
plot(tree_model)
text(tree_model, digits=1)
rpart.plot(tree_model, extra = 1)
# Make predictions
predictions <- predict(tree_model, newdata = test_data)
# Extract actual salary values
actual_salary <- test_data$salary_in_usd
# Check for missing values
sum(is.na(actual_salary))
sum(is.na(predictions))
# Remove missing values
complete_cases <- complete.cases(actual_salary, predictions)
actual_salary <- actual_salary[complete_cases]
predictions <- predictions[complete_cases]
# Calculate RMSE
rmse <- sqrt(mean((predictions - actual_salary)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
Salary <- read.csv("salaries.csv")
Q1 <- quantile(Salary$salary_in_usd, 0.25)
Q3 <- quantile(Salary$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
Salary <- Salary[Salary$salary_in_usd >= lower_bound & Salary$salary_in_usd <= upper_bound, ]
Salary <- Salary %>%
filter(work_year %in% c(2022, 2023), company_location == "US")
# Set seed for reproducibility
set.seed(123)
# Sample indices for training set
train_indices <- sample(1:nrow(Salary), 0.8 * nrow(Salary))
# Create training and testing datasets
train_data <- Salary[train_indices, ]
test_data <- Salary[-train_indices, ]
# Convert factor variables to factors with consistent levels
factor_vars <- c("experience_level", "job_title", "salary_currency", "employee_residence", "company_size", "company_location", "employment_type")
for (var in factor_vars) {
train_data[[var]] <- as.factor(train_data[[var]])
test_data[[var]] <- as.factor(test_data[[var]])
}
# Ensure factor levels in newdata match the training data
for (var in factor_vars) {
test_data[[var]] <- factor(test_data[[var]], levels = levels(train_data[[var]]))
}
# Build the model
tree_model <- rpart(salary_in_usd ~ work_year + experience_level + employment_type + job_title + employee_residence + remote_ratio + company_location + company_size, data = train_data)
plot(tree_model)
text(tree_model, digits=1)
rpart.plot(tree_model, extra = 1)
# Make predictions
predictions <- predict(tree_model, newdata = test_data)
# Extract actual salary values
actual_salary <- test_data$salary_in_usd
# Check for missing values
sum(is.na(actual_salary))
sum(is.na(predictions))
# Remove missing values
complete_cases <- complete.cases(actual_salary, predictions)
actual_salary <- actual_salary[complete_cases]
predictions <- predictions[complete_cases]
# Calculate RMSE
rmse <- sqrt(mean((predictions - actual_salary)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
Salary <- read.csv("salaries.csv")
Q1 <- quantile(Salary$salary_in_usd, 0.25)
Q3 <- quantile(Salary$salary_in_usd, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
Salary <- Salary[Salary$salary_in_usd >= lower_bound & Salary$salary_in_usd <= upper_bound, ]
Salary <- Salary %>%
filter(work_year %in% c(2022, 2023), company_location == "US")
Salary %>%
filter(work_year == 2022) %>%
summarize(avgsal = mean(salary_in_usd))
for (i in 1:nrow(Salary)) {
if (Salary$work_year[i] == 2022) {
Salary$work_year[i] <- Salary$work_year[i] * 1.08
}
}
Salary %>%
filter(work_year == 2022) %>%
summarize(avgsal = mean(salary_in_usd))
View(Salary)
